{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM\n",
    "from keras.optimizers import *\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date='2018-07-05'\n",
    "# Get normalized model_data\n",
    "model_data=pd.read_csv(\"model_data.csv\").iloc[:, 1:]\n",
    "\n",
    "training_set, test_set = model_data[model_data['Date']<split_date], model_data[model_data['Date']>=split_date]\n",
    "training_set = training_set.drop('Date', 1)\n",
    "test_set = test_set.drop('Date', 1)\n",
    "\n",
    "window_len = 35\n",
    "# norm_cols = [coin+metric for coin in ['bt_'] for metric in ['Close','Volume', 'google_trends_bitcoin', 'avg_block_size', 'transactions']]\n",
    "\n",
    "norm_cols = [coin+metric for coin in ['bt_'] for metric in ['Close','Volume', 'google_trends_bitcoin']]\n",
    "\n",
    "# norm_cols = [coin+metric for coin in ['bt_'] for metric in ['Close','Volume']]\n",
    "\n",
    "\n",
    "LSTM_training_inputs = []\n",
    "for i in range(len(training_set)-window_len):\n",
    "    temp_set = training_set[i:(i+window_len)].copy()\n",
    "    LSTM_training_inputs.append(temp_set)   \n",
    "\n",
    "LSTM_test_inputs = []\n",
    "for i in range(len(test_set)-window_len):\n",
    "    temp_set = test_set[i:(i+window_len)].copy()\n",
    "    LSTM_test_inputs.append(temp_set)\n",
    "    \n",
    "LSTM_training_inputs = [np.array(LSTM_training_input) for LSTM_training_input in LSTM_training_inputs]\n",
    "LSTM_training_inputs = np.array(LSTM_training_inputs)\n",
    "\n",
    "LSTM_test_inputs = [np.array(LSTM_test_inputs) for LSTM_test_inputs in LSTM_test_inputs]\n",
    "LSTM_test_inputs = np.array(LSTM_test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shape: (1689, 10, 24)\n",
    "# print(LSTM_training_inputs[:-pred_range].shape)\n",
    "\n",
    "# print(len(LSTM_training_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# %load models/lstm_model.py\n",
    "\"\"\"\n",
    "    If network is overfitting => decrease batch size; the contrary is true for underfitting\n",
    "\"\"\"\n",
    "def lstm_model(neurons, optimizer, loss, activ_func, dropout): \n",
    "    keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(100,22)))\n",
    "    model.add(Dropout(dropout))\n",
    "    # Units is the length of output vector, which in turn is the pred_range\n",
    "    model.add(Dense(units=50))\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.optimizers.SGD'>\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "print(optimizers.SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [20, 50, 100][:1]\n",
    "epochs = [20, 50, 100][:1]\n",
    "neurons = [10, 20, 30][:1]\n",
    "optimizer = ['sgd','adam'][:1]\n",
    "loss=['mae','mean_squared_error']\n",
    "activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'][:1]\n",
    "dropout_rate = [0.3, 0.25, 0.8][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Wrapper and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the wrapper and pass params to GridSearchCV\n",
    "params = dict(neurons = neurons,\n",
    "              optimizer = optimizer,\n",
    "              loss = loss,\n",
    "              activ_func = activation,\n",
    "              dropout = dropout_rate)\n",
    "\n",
    "model = KerasRegressor(build_fn=lstm_model,  verbose=2, shuffle=True, batch_size = 100,\n",
    "                        epochs = 100)\n",
    "\n",
    "models = GridSearchCV(estimator = model, param_grid=params,scoring = 'neg_mean_squared_error', n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559\n",
      "1559\n"
     ]
    }
   ],
   "source": [
    "print(len(LSTM_training_inputs[:-pred_range]))\n",
    "print(len(LSTM_training_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 0.6580\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.6578\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6565\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6556\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.6548\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.6541\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.6538\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6530\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.6525\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.6510\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.6511\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.6508\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.6509\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.6497\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.6492\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.6486\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.6474\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.6477\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.6468\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.6465\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.6459\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.6458\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.6449\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.6448\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.6434\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.6442\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.6436\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.6423\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.6413\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.6409\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.6407\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.6408\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.6394\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.6393\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.6392\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.6393\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.6379\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.6378\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.6382\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.6365\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.6366\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.6366\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.6346\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.6349\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.6352\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.6339\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.6340\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.6330\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.6322\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.6319\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.6319\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.6307\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.6310\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.6312\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.6309\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.6299\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.6292\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.6283\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.6289\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.6285\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.6278\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.6272\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.6268\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.6252\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.6260\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.6240\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.6236\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.6233\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.6260\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.6243\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.6225\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.6222\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.6226\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.6234\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.6215\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.6218\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.6197\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.6206\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.6185\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.6180\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.6193\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.6165\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.6162\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.6166\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.6167\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.6156\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.6147\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.6154\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.6140\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.6131\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.6147\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.6116\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.6131\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.6117\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.6107\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.6104\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.6100\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.6087\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.6081\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.6087\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.5391\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.5383\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2.5376\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.5372\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.5367\n",
      "Epoch 6/100\n",
      " - 1s - loss: 2.5358\n",
      "Epoch 7/100\n",
      " - 1s - loss: 2.5355\n",
      "Epoch 8/100\n",
      " - 1s - loss: 2.5350\n",
      "Epoch 9/100\n",
      " - 1s - loss: 2.5340\n",
      "Epoch 10/100\n",
      " - 1s - loss: 2.5330\n",
      "Epoch 11/100\n",
      " - 0s - loss: 2.5323\n",
      "Epoch 12/100\n",
      " - 0s - loss: 2.5323\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.5308\n",
      "Epoch 14/100\n",
      " - 1s - loss: 2.5301\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.5291\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.5282\n",
      "Epoch 17/100\n",
      " - 0s - loss: 2.5279\n",
      "Epoch 18/100\n",
      " - 0s - loss: 2.5263\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.5270\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.5254\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.5251\n",
      "Epoch 22/100\n",
      " - 1s - loss: 2.5248\n",
      "Epoch 23/100\n",
      " - 1s - loss: 2.5236\n",
      "Epoch 24/100\n",
      " - 1s - loss: 2.5227\n",
      "Epoch 25/100\n",
      " - 1s - loss: 2.5226\n",
      "Epoch 26/100\n",
      " - 1s - loss: 2.5221\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.5213\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.5207\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.5194\n",
      "Epoch 30/100\n",
      " - 1s - loss: 2.5192\n",
      "Epoch 31/100\n",
      " - 1s - loss: 2.5198\n",
      "Epoch 32/100\n",
      " - 1s - loss: 2.5182\n",
      "Epoch 33/100\n",
      " - 1s - loss: 2.5195\n",
      "Epoch 34/100\n",
      " - 1s - loss: 2.5166\n",
      "Epoch 35/100\n",
      " - 1s - loss: 2.5164\n",
      "Epoch 36/100\n",
      " - 1s - loss: 2.5158\n",
      "Epoch 37/100\n",
      " - 1s - loss: 2.5155\n",
      "Epoch 38/100\n",
      " - 1s - loss: 2.5153\n",
      "Epoch 39/100\n",
      " - 1s - loss: 2.5151\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.5134\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.5142\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.5137\n",
      "Epoch 43/100\n",
      " - 1s - loss: 2.5136\n",
      "Epoch 44/100\n",
      " - 1s - loss: 2.5118\n",
      "Epoch 45/100\n",
      " - 1s - loss: 2.5131\n",
      "Epoch 46/100\n",
      " - 1s - loss: 2.5114\n",
      "Epoch 47/100\n",
      " - 1s - loss: 2.5115\n",
      "Epoch 48/100\n",
      " - 1s - loss: 2.5106\n",
      "Epoch 49/100\n",
      " - 1s - loss: 2.5109\n",
      "Epoch 50/100\n",
      " - 1s - loss: 2.5098\n",
      "Epoch 51/100\n",
      " - 1s - loss: 2.5096\n",
      "Epoch 52/100\n",
      " - 1s - loss: 2.5090\n",
      "Epoch 53/100\n",
      " - 1s - loss: 2.5085\n",
      "Epoch 54/100\n",
      " - 1s - loss: 2.5081\n",
      "Epoch 55/100\n",
      " - 1s - loss: 2.5081\n",
      "Epoch 56/100\n",
      " - 1s - loss: 2.5074\n",
      "Epoch 57/100\n",
      " - 0s - loss: 2.5066\n",
      "Epoch 58/100\n",
      " - 0s - loss: 2.5057\n",
      "Epoch 59/100\n",
      " - 0s - loss: 2.5061\n",
      "Epoch 60/100\n",
      " - 0s - loss: 2.5061\n",
      "Epoch 61/100\n",
      " - 0s - loss: 2.5071\n",
      "Epoch 62/100\n",
      " - 0s - loss: 2.5048\n",
      "Epoch 63/100\n",
      " - 0s - loss: 2.5039\n",
      "Epoch 64/100\n",
      " - 0s - loss: 2.5041\n",
      "Epoch 65/100\n",
      " - 0s - loss: 2.5037\n",
      "Epoch 66/100\n",
      " - 0s - loss: 2.5036\n",
      "Epoch 67/100\n",
      " - 0s - loss: 2.5037\n",
      "Epoch 68/100\n",
      " - 0s - loss: 2.5031\n",
      "Epoch 69/100\n",
      " - 1s - loss: 2.5028\n",
      "Epoch 70/100\n",
      " - 0s - loss: 2.5037\n",
      "Epoch 71/100\n",
      " - 0s - loss: 2.5016\n",
      "Epoch 72/100\n",
      " - 1s - loss: 2.5005\n",
      "Epoch 73/100\n",
      " - 1s - loss: 2.5021\n",
      "Epoch 74/100\n",
      " - 1s - loss: 2.5008\n",
      "Epoch 75/100\n",
      " - 1s - loss: 2.5000\n",
      "Epoch 76/100\n",
      " - 0s - loss: 2.4988\n",
      "Epoch 77/100\n",
      " - 0s - loss: 2.4981\n",
      "Epoch 78/100\n",
      " - 1s - loss: 2.4998\n",
      "Epoch 79/100\n",
      " - 1s - loss: 2.4994\n",
      "Epoch 80/100\n",
      " - 0s - loss: 2.4974\n",
      "Epoch 81/100\n",
      " - 1s - loss: 2.4970\n",
      "Epoch 82/100\n",
      " - 1s - loss: 2.4953\n",
      "Epoch 83/100\n",
      " - 1s - loss: 2.4967\n",
      "Epoch 84/100\n",
      " - 1s - loss: 2.4960\n",
      "Epoch 85/100\n",
      " - 1s - loss: 2.4965\n",
      "Epoch 86/100\n",
      " - 1s - loss: 2.4959\n",
      "Epoch 87/100\n",
      " - 1s - loss: 2.4966\n",
      "Epoch 88/100\n",
      " - 1s - loss: 2.4951\n",
      "Epoch 89/100\n",
      " - 0s - loss: 2.4944\n",
      "Epoch 90/100\n",
      " - 1s - loss: 2.4943\n",
      "Epoch 91/100\n",
      " - 0s - loss: 2.4942\n",
      "Epoch 92/100\n",
      " - 0s - loss: 2.4934\n",
      "Epoch 93/100\n",
      " - 0s - loss: 2.4937\n",
      "Epoch 94/100\n",
      " - 1s - loss: 2.4917\n",
      "Epoch 95/100\n",
      " - 1s - loss: 2.4906\n",
      "Epoch 96/100\n",
      " - 1s - loss: 2.4919\n",
      "Epoch 97/100\n",
      " - 1s - loss: 2.4912\n",
      "Epoch 98/100\n",
      " - 1s - loss: 2.4894\n",
      "Epoch 99/100\n",
      " - 1s - loss: 2.4902\n",
      "Epoch 100/100\n",
      " - 1s - loss: 2.4892\n",
      "Epoch 1/100\n",
      " - 1s - loss: 2.2528\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.2527\n",
      "Epoch 3/100\n",
      " - 1s - loss: 2.2527\n",
      "Epoch 4/100\n",
      " - 1s - loss: 2.2527\n",
      "Epoch 5/100\n",
      " - 1s - loss: 2.2524\n",
      "Epoch 6/100\n",
      " - 1s - loss: 2.2517\n",
      "Epoch 7/100\n",
      " - 1s - loss: 2.2526\n",
      "Epoch 8/100\n",
      " - 1s - loss: 2.2521\n",
      "Epoch 9/100\n",
      " - 1s - loss: 2.2519\n",
      "Epoch 10/100\n",
      " - 0s - loss: 2.2516\n",
      "Epoch 11/100\n",
      " - 0s - loss: 2.2520\n",
      "Epoch 12/100\n",
      " - 1s - loss: 2.2525\n",
      "Epoch 13/100\n",
      " - 1s - loss: 2.2515\n",
      "Epoch 14/100\n",
      " - 1s - loss: 2.2519\n",
      "Epoch 15/100\n",
      " - 1s - loss: 2.2519\n",
      "Epoch 16/100\n",
      " - 1s - loss: 2.2516\n",
      "Epoch 17/100\n",
      " - 1s - loss: 2.2519\n",
      "Epoch 18/100\n",
      " - 1s - loss: 2.2519\n",
      "Epoch 19/100\n",
      " - 1s - loss: 2.2519\n",
      "Epoch 20/100\n",
      " - 1s - loss: 2.2513\n",
      "Epoch 21/100\n",
      " - 1s - loss: 2.2513\n",
      "Epoch 22/100\n",
      " - 1s - loss: 2.2516\n",
      "Epoch 23/100\n",
      " - 1s - loss: 2.2514\n",
      "Epoch 24/100\n",
      " - 1s - loss: 2.2516\n",
      "Epoch 25/100\n",
      " - 1s - loss: 2.2513\n",
      "Epoch 26/100\n",
      " - 1s - loss: 2.2516\n",
      "Epoch 27/100\n",
      " - 1s - loss: 2.2519\n",
      "Epoch 28/100\n",
      " - 1s - loss: 2.2516\n",
      "Epoch 29/100\n",
      " - 1s - loss: 2.2513\n",
      "Epoch 30/100\n",
      " - 1s - loss: 2.2510\n",
      "Epoch 31/100\n",
      " - 0s - loss: 2.2512\n",
      "Epoch 32/100\n",
      " - 0s - loss: 2.2513\n",
      "Epoch 33/100\n",
      " - 1s - loss: 2.2516\n",
      "Epoch 34/100\n",
      " - 1s - loss: 2.2507\n",
      "Epoch 35/100\n",
      " - 1s - loss: 2.2507\n",
      "Epoch 36/100\n",
      " - 1s - loss: 2.2508\n",
      "Epoch 37/100\n",
      " - 1s - loss: 2.2506\n",
      "Epoch 38/100\n",
      " - 1s - loss: 2.2505\n",
      "Epoch 39/100\n",
      " - 1s - loss: 2.2510\n",
      "Epoch 40/100\n",
      " - 1s - loss: 2.2510\n",
      "Epoch 41/100\n",
      " - 1s - loss: 2.2507\n",
      "Epoch 42/100\n",
      " - 1s - loss: 2.2508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      " - 1s - loss: 2.2502\n",
      "Epoch 44/100\n",
      " - 1s - loss: 2.2511\n",
      "Epoch 45/100\n",
      " - 1s - loss: 2.2502\n",
      "Epoch 46/100\n",
      " - 1s - loss: 2.2506\n",
      "Epoch 47/100\n",
      " - 1s - loss: 2.2504\n",
      "Epoch 48/100\n",
      " - 1s - loss: 2.2508\n",
      "Epoch 49/100\n",
      " - 1s - loss: 2.2503\n",
      "Epoch 50/100\n",
      " - 1s - loss: 2.2502\n",
      "Epoch 51/100\n",
      " - 1s - loss: 2.2503\n",
      "Epoch 52/100\n",
      " - 1s - loss: 2.2497\n",
      "Epoch 53/100\n",
      " - 1s - loss: 2.2503\n",
      "Epoch 54/100\n",
      " - 1s - loss: 2.2500\n",
      "Epoch 55/100\n",
      " - 1s - loss: 2.2498\n",
      "Epoch 56/100\n",
      " - 1s - loss: 2.2503\n",
      "Epoch 57/100\n",
      " - 1s - loss: 2.2500\n",
      "Epoch 58/100\n",
      " - 1s - loss: 2.2503\n",
      "Epoch 59/100\n",
      " - 1s - loss: 2.2497\n",
      "Epoch 60/100\n",
      " - 1s - loss: 2.2496\n",
      "Epoch 61/100\n",
      " - 1s - loss: 2.2491\n",
      "Epoch 62/100\n",
      " - 1s - loss: 2.2500\n",
      "Epoch 63/100\n",
      " - 1s - loss: 2.2501\n",
      "Epoch 64/100\n",
      " - 1s - loss: 2.2494\n",
      "Epoch 65/100\n",
      " - 1s - loss: 2.2492\n",
      "Epoch 66/100\n",
      " - 1s - loss: 2.2497\n",
      "Epoch 67/100\n",
      " - 0s - loss: 2.2496\n",
      "Epoch 68/100\n",
      " - 0s - loss: 2.2495\n",
      "Epoch 69/100\n",
      " - 0s - loss: 2.2496\n",
      "Epoch 70/100\n",
      " - 1s - loss: 2.2500\n",
      "Epoch 71/100\n",
      " - 1s - loss: 2.2496\n",
      "Epoch 72/100\n",
      " - 1s - loss: 2.2493\n",
      "Epoch 73/100\n",
      " - 1s - loss: 2.2498\n",
      "Epoch 74/100\n",
      " - 0s - loss: 2.2496\n",
      "Epoch 75/100\n",
      " - 1s - loss: 2.2492\n",
      "Epoch 76/100\n",
      " - 1s - loss: 2.2490\n",
      "Epoch 77/100\n",
      " - 1s - loss: 2.2492\n",
      "Epoch 78/100\n",
      " - 1s - loss: 2.2494\n",
      "Epoch 79/100\n",
      " - 1s - loss: 2.2492\n",
      "Epoch 80/100\n",
      " - 1s - loss: 2.2492\n",
      "Epoch 81/100\n",
      " - 1s - loss: 2.2493\n",
      "Epoch 82/100\n",
      " - 1s - loss: 2.2490\n",
      "Epoch 83/100\n",
      " - 1s - loss: 2.2497\n",
      "Epoch 84/100\n",
      " - 1s - loss: 2.2491\n",
      "Epoch 85/100\n",
      " - 1s - loss: 2.2491\n",
      "Epoch 86/100\n",
      " - 1s - loss: 2.2492\n",
      "Epoch 87/100\n",
      " - 1s - loss: 2.2491\n",
      "Epoch 88/100\n",
      " - 1s - loss: 2.2493\n",
      "Epoch 89/100\n",
      " - 1s - loss: 2.2486\n",
      "Epoch 90/100\n",
      " - 1s - loss: 2.2493\n",
      "Epoch 91/100\n",
      " - 1s - loss: 2.2487\n",
      "Epoch 92/100\n",
      " - 1s - loss: 2.2492\n",
      "Epoch 93/100\n",
      " - 1s - loss: 2.2488\n",
      "Epoch 94/100\n",
      " - 1s - loss: 2.2489\n",
      "Epoch 95/100\n",
      " - 1s - loss: 2.2490\n",
      "Epoch 96/100\n",
      " - 1s - loss: 2.2486\n",
      "Epoch 97/100\n",
      " - 1s - loss: 2.2484\n",
      "Epoch 98/100\n",
      " - 1s - loss: 2.2482\n",
      "Epoch 99/100\n",
      " - 1s - loss: 2.2481\n",
      "Epoch 100/100\n",
      " - 1s - loss: 2.2483\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.9702\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.9673\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.9647\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.9646\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.9610\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.9580\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.9566\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.9540\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.9513\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.9484\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.9456\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.9439\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.9424\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.9389\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.9374\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.9358\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.9314\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.9314\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.9277\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.9250\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.9230\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.9218\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.9195\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.9158\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.9158\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.9128\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.9102\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.9076\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.9077\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.9040\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.9026\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.9001\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.8995\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.8968\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.8967\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.8897\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.8893\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.8851\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.8852\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.8830\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.8834\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.8798\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.8803\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.8795\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.8771\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.8746\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.8714\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.8676\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.8648\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.8651\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.8629\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.8624\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.8578\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.8571\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.8524\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.8574\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.8504\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.8497\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.8464\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.8455\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.8442\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.8426\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.8370\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.8375\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.8377\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.8351\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.8338\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.8307\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.8284\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.8258\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.8253\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.8237\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.8231\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.8246\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.8170\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.8176\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.8162\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.8124\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.8130\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.8118\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.8057\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.8048\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.8012\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.8052\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.7962\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.7994\n",
      "Epoch 87/100\n",
      " - 1s - loss: 0.7992\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.7927\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.7897\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.7942\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.7908\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.7849\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.7820\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.7821\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.7854\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.7790\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.7796\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.7779\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.7761\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.7706\n",
      "Epoch 1/100\n",
      " - 1s - loss: 101.3343\n",
      "Epoch 2/100\n",
      " - 1s - loss: 101.2814\n",
      "Epoch 3/100\n",
      " - 1s - loss: 101.2098\n",
      "Epoch 4/100\n",
      " - 1s - loss: 101.1458\n",
      "Epoch 5/100\n",
      " - 1s - loss: 101.0762\n",
      "Epoch 6/100\n",
      " - 1s - loss: 101.0141\n",
      "Epoch 7/100\n",
      " - 1s - loss: 100.9425\n",
      "Epoch 8/100\n",
      " - 1s - loss: 100.8870\n",
      "Epoch 9/100\n",
      " - 1s - loss: 100.8303\n",
      "Epoch 10/100\n",
      " - 1s - loss: 100.7129\n",
      "Epoch 11/100\n",
      " - 1s - loss: 100.6156\n",
      "Epoch 12/100\n",
      " - 1s - loss: 100.5081\n",
      "Epoch 13/100\n",
      " - 1s - loss: 100.5109\n",
      "Epoch 14/100\n",
      " - 1s - loss: 100.4043\n",
      "Epoch 15/100\n",
      " - 1s - loss: 100.3567\n",
      "Epoch 16/100\n",
      " - 1s - loss: 100.2227\n",
      "Epoch 17/100\n",
      " - 1s - loss: 100.1375\n",
      "Epoch 18/100\n",
      " - 1s - loss: 99.9969\n",
      "Epoch 19/100\n",
      " - 1s - loss: 99.9133\n",
      "Epoch 20/100\n",
      " - 1s - loss: 99.8020\n",
      "Epoch 21/100\n",
      " - 1s - loss: 99.7718\n",
      "Epoch 22/100\n",
      " - 1s - loss: 99.6313\n",
      "Epoch 23/100\n",
      " - 1s - loss: 99.4598\n",
      "Epoch 24/100\n",
      " - 1s - loss: 99.3562\n",
      "Epoch 25/100\n",
      " - 1s - loss: 99.3258\n",
      "Epoch 26/100\n",
      " - 1s - loss: 99.1873\n",
      "Epoch 27/100\n",
      " - 1s - loss: 99.0657\n",
      "Epoch 28/100\n",
      " - 1s - loss: 98.9127\n",
      "Epoch 29/100\n",
      " - 1s - loss: 98.8022\n",
      "Epoch 30/100\n",
      " - 1s - loss: 98.5613\n",
      "Epoch 31/100\n",
      " - 1s - loss: 98.6010\n",
      "Epoch 32/100\n",
      " - 0s - loss: 98.3533\n",
      "Epoch 33/100\n",
      " - 1s - loss: 98.3457\n",
      "Epoch 34/100\n",
      " - 1s - loss: 98.1035\n",
      "Epoch 35/100\n",
      " - 0s - loss: 97.9883\n",
      "Epoch 36/100\n",
      " - 1s - loss: 97.8419\n",
      "Epoch 37/100\n",
      " - 1s - loss: 97.8634\n",
      "Epoch 38/100\n",
      " - 1s - loss: 97.6383\n",
      "Epoch 39/100\n",
      " - 1s - loss: 97.4436\n",
      "Epoch 40/100\n",
      " - 1s - loss: 97.2465\n",
      "Epoch 41/100\n",
      " - 1s - loss: 97.1640\n",
      "Epoch 42/100\n",
      " - 1s - loss: 97.1049\n",
      "Epoch 43/100\n",
      " - 1s - loss: 96.8421\n",
      "Epoch 44/100\n",
      " - 1s - loss: 96.7120\n",
      "Epoch 45/100\n",
      " - 1s - loss: 96.8022\n",
      "Epoch 46/100\n",
      " - 1s - loss: 96.6641\n",
      "Epoch 47/100\n",
      " - 1s - loss: 96.2399\n",
      "Epoch 48/100\n",
      " - 1s - loss: 96.4618\n",
      "Epoch 49/100\n",
      " - 1s - loss: 96.0039\n",
      "Epoch 50/100\n",
      " - 1s - loss: 95.8721\n",
      "Epoch 51/100\n",
      " - 1s - loss: 95.8323\n",
      "Epoch 52/100\n",
      " - 1s - loss: 95.9744\n",
      "Epoch 53/100\n",
      " - 1s - loss: 95.5958\n",
      "Epoch 54/100\n",
      " - 1s - loss: 95.6812\n",
      "Epoch 55/100\n",
      " - 1s - loss: 96.8011\n",
      "Epoch 56/100\n",
      " - 1s - loss: 96.0968\n",
      "Epoch 57/100\n",
      " - 1s - loss: 97.1948\n",
      "Epoch 58/100\n",
      " - 1s - loss: 96.2795\n",
      "Epoch 59/100\n",
      " - 1s - loss: 96.7729\n",
      "Epoch 60/100\n",
      " - 1s - loss: 96.6964\n",
      "Epoch 61/100\n",
      " - 1s - loss: 96.2186\n",
      "Epoch 62/100\n",
      " - 1s - loss: 96.5529\n",
      "Epoch 63/100\n",
      " - 1s - loss: 97.3722\n",
      "Epoch 64/100\n",
      " - 1s - loss: 96.0443\n",
      "Epoch 65/100\n",
      " - 1s - loss: 95.9876\n",
      "Epoch 66/100\n",
      " - 1s - loss: 96.1085\n",
      "Epoch 67/100\n",
      " - 1s - loss: 96.1775\n",
      "Epoch 68/100\n",
      " - 1s - loss: 96.3288\n",
      "Epoch 69/100\n",
      " - 1s - loss: 96.3919\n",
      "Epoch 70/100\n",
      " - 1s - loss: 96.5676\n",
      "Epoch 71/100\n",
      " - 0s - loss: 96.4001\n",
      "Epoch 72/100\n",
      " - 1s - loss: 95.8724\n",
      "Epoch 73/100\n",
      " - 1s - loss: 96.3974\n",
      "Epoch 74/100\n",
      " - 1s - loss: 96.2409\n",
      "Epoch 75/100\n",
      " - 1s - loss: 95.9964\n",
      "Epoch 76/100\n",
      " - 1s - loss: 96.0555\n",
      "Epoch 77/100\n",
      " - 1s - loss: 95.8237\n",
      "Epoch 78/100\n",
      " - 1s - loss: 96.2392\n",
      "Epoch 79/100\n",
      " - 1s - loss: 94.8787\n",
      "Epoch 80/100\n",
      " - 1s - loss: 95.7055\n",
      "Epoch 81/100\n",
      " - 1s - loss: 94.2794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      " - 1s - loss: 95.5040\n",
      "Epoch 83/100\n",
      " - 1s - loss: 94.5177\n",
      "Epoch 84/100\n",
      " - 1s - loss: 94.9503\n",
      "Epoch 85/100\n",
      " - 1s - loss: 94.7171\n",
      "Epoch 86/100\n",
      " - 1s - loss: 94.0970\n",
      "Epoch 87/100\n",
      " - 1s - loss: 93.8103\n",
      "Epoch 88/100\n",
      " - 1s - loss: 96.5969\n",
      "Epoch 89/100\n",
      " - 1s - loss: 95.4143\n",
      "Epoch 90/100\n",
      " - 1s - loss: 95.8736\n",
      "Epoch 91/100\n",
      " - 1s - loss: 95.5093\n",
      "Epoch 92/100\n",
      " - 1s - loss: 95.7825\n",
      "Epoch 93/100\n",
      " - 1s - loss: 95.7457\n",
      "Epoch 94/100\n",
      " - 1s - loss: 95.4362\n",
      "Epoch 95/100\n",
      " - 1s - loss: 95.3809\n",
      "Epoch 96/100\n",
      " - 1s - loss: 95.6098\n",
      "Epoch 97/100\n",
      " - 1s - loss: 95.5049\n",
      "Epoch 98/100\n",
      " - 1s - loss: 95.5153\n",
      "Epoch 99/100\n",
      " - 1s - loss: 95.2203\n",
      "Epoch 100/100\n",
      " - 1s - loss: 94.8617\n",
      "Epoch 1/100\n",
      " - 1s - loss: 100.5558\n",
      "Epoch 2/100\n",
      " - 0s - loss: 100.5268\n",
      "Epoch 3/100\n",
      " - 1s - loss: 100.4896\n",
      "Epoch 4/100\n",
      " - 1s - loss: 100.4584\n",
      "Epoch 5/100\n",
      " - 1s - loss: 100.3852\n",
      "Epoch 6/100\n",
      " - 1s - loss: 100.3210\n",
      "Epoch 7/100\n",
      " - 1s - loss: 100.2334\n",
      "Epoch 8/100\n",
      " - 1s - loss: 100.1914\n",
      "Epoch 9/100\n",
      " - 1s - loss: 100.1267\n",
      "Epoch 10/100\n",
      " - 1s - loss: 100.0567\n",
      "Epoch 11/100\n",
      " - 1s - loss: 100.0283\n",
      "Epoch 12/100\n",
      " - 1s - loss: 99.9314\n",
      "Epoch 13/100\n",
      " - 1s - loss: 99.8390\n",
      "Epoch 14/100\n",
      " - 1s - loss: 99.7382\n",
      "Epoch 15/100\n",
      " - 1s - loss: 99.6939\n",
      "Epoch 16/100\n",
      " - 1s - loss: 99.6470\n",
      "Epoch 17/100\n",
      " - 1s - loss: 99.5304\n",
      "Epoch 18/100\n",
      " - 1s - loss: 99.4814\n",
      "Epoch 19/100\n",
      " - 1s - loss: 99.3898\n",
      "Epoch 20/100\n",
      " - 1s - loss: 99.3831\n",
      "Epoch 21/100\n",
      " - 1s - loss: 99.2847\n",
      "Epoch 22/100\n",
      " - 1s - loss: 99.2148\n",
      "Epoch 23/100\n",
      " - 1s - loss: 99.1199\n",
      "Epoch 24/100\n",
      " - 1s - loss: 98.9551\n",
      "Epoch 25/100\n",
      " - 1s - loss: 99.0263\n",
      "Epoch 26/100\n",
      " - 1s - loss: 98.9600\n",
      "Epoch 27/100\n",
      " - 1s - loss: 98.8435\n",
      "Epoch 28/100\n",
      " - 1s - loss: 98.6450\n",
      "Epoch 29/100\n",
      " - 1s - loss: 98.6365\n",
      "Epoch 30/100\n",
      " - 1s - loss: 98.5874\n",
      "Epoch 31/100\n",
      " - 1s - loss: 98.4116\n",
      "Epoch 32/100\n",
      " - 1s - loss: 98.3930\n",
      "Epoch 33/100\n",
      " - 1s - loss: 98.1474\n",
      "Epoch 34/100\n",
      " - 1s - loss: 98.0367\n",
      "Epoch 35/100\n",
      " - 1s - loss: 97.9576\n",
      "Epoch 36/100\n",
      " - 1s - loss: 97.9079\n",
      "Epoch 37/100\n",
      " - 1s - loss: 97.6912\n",
      "Epoch 38/100\n",
      " - 1s - loss: 97.5278\n",
      "Epoch 39/100\n",
      " - 1s - loss: 97.3742\n",
      "Epoch 40/100\n",
      " - 1s - loss: 97.2974\n",
      "Epoch 41/100\n",
      " - 1s - loss: 97.1688\n",
      "Epoch 42/100\n",
      " - 0s - loss: 96.8260\n",
      "Epoch 43/100\n",
      " - 0s - loss: 96.7534\n",
      "Epoch 44/100\n",
      " - 0s - loss: 96.7427\n",
      "Epoch 45/100\n",
      " - 1s - loss: 96.5443\n",
      "Epoch 46/100\n",
      " - 1s - loss: 96.3898\n",
      "Epoch 47/100\n",
      " - 1s - loss: 96.1585\n",
      "Epoch 48/100\n",
      " - 1s - loss: 96.0911\n",
      "Epoch 49/100\n",
      " - 1s - loss: 95.9192\n",
      "Epoch 50/100\n",
      " - 1s - loss: 95.9809\n",
      "Epoch 51/100\n",
      " - 1s - loss: 95.6711\n",
      "Epoch 52/100\n",
      " - 1s - loss: 96.0659\n",
      "Epoch 53/100\n",
      " - 1s - loss: 95.8071\n",
      "Epoch 54/100\n",
      " - 1s - loss: 96.6141\n",
      "Epoch 55/100\n",
      " - 1s - loss: 97.3963\n",
      "Epoch 56/100\n",
      " - 1s - loss: 97.2512\n",
      "Epoch 57/100\n",
      " - 1s - loss: 97.1017\n",
      "Epoch 58/100\n",
      " - 1s - loss: 96.7915\n",
      "Epoch 59/100\n",
      " - 1s - loss: 96.3619\n",
      "Epoch 60/100\n",
      " - 1s - loss: 95.8429\n",
      "Epoch 61/100\n",
      " - 1s - loss: 96.1745\n",
      "Epoch 62/100\n",
      " - 1s - loss: 95.3154\n",
      "Epoch 63/100\n",
      " - 1s - loss: 94.9761\n",
      "Epoch 64/100\n",
      " - 1s - loss: 95.1826\n",
      "Epoch 65/100\n",
      " - 1s - loss: 95.0039\n",
      "Epoch 66/100\n",
      " - 1s - loss: 95.1312\n",
      "Epoch 67/100\n",
      " - 1s - loss: 95.8402\n",
      "Epoch 68/100\n",
      " - 1s - loss: 95.1005\n",
      "Epoch 69/100\n",
      " - 1s - loss: 94.6363\n",
      "Epoch 70/100\n",
      " - 1s - loss: 94.7769\n",
      "Epoch 71/100\n",
      " - 1s - loss: 94.3554\n",
      "Epoch 72/100\n",
      " - 1s - loss: 94.2851\n",
      "Epoch 73/100\n",
      " - 1s - loss: 95.1837\n",
      "Epoch 74/100\n",
      " - 1s - loss: 94.6393\n",
      "Epoch 75/100\n",
      " - 1s - loss: 94.1828\n",
      "Epoch 76/100\n",
      " - 1s - loss: 94.4336\n",
      "Epoch 77/100\n",
      " - 1s - loss: 93.7947\n",
      "Epoch 78/100\n",
      " - 1s - loss: 93.5415\n",
      "Epoch 79/100\n",
      " - 1s - loss: 94.3671\n",
      "Epoch 80/100\n",
      " - 1s - loss: 94.2471\n",
      "Epoch 81/100\n",
      " - 1s - loss: 93.5547\n",
      "Epoch 82/100\n",
      " - 1s - loss: 93.2168\n",
      "Epoch 83/100\n",
      " - 1s - loss: 92.1233\n",
      "Epoch 84/100\n",
      " - 1s - loss: 92.3947\n",
      "Epoch 85/100\n",
      " - 0s - loss: 92.9602\n",
      "Epoch 86/100\n",
      " - 0s - loss: 92.0205\n",
      "Epoch 87/100\n",
      " - 0s - loss: 91.8206\n",
      "Epoch 88/100\n",
      " - 0s - loss: 95.8661\n",
      "Epoch 89/100\n",
      " - 0s - loss: 93.9307\n",
      "Epoch 90/100\n",
      " - 1s - loss: 93.8883\n",
      "Epoch 91/100\n",
      " - 1s - loss: 94.7174\n",
      "Epoch 92/100\n",
      " - 1s - loss: 94.1636\n",
      "Epoch 93/100\n",
      " - 1s - loss: 93.1069\n",
      "Epoch 94/100\n",
      " - 1s - loss: 93.6532\n",
      "Epoch 95/100\n",
      " - 1s - loss: 94.2020\n",
      "Epoch 96/100\n",
      " - 1s - loss: 92.7328\n",
      "Epoch 97/100\n",
      " - 1s - loss: 93.0917\n",
      "Epoch 98/100\n",
      " - 1s - loss: 92.7694\n",
      "Epoch 99/100\n",
      " - 1s - loss: 92.1026\n",
      "Epoch 100/100\n",
      " - 1s - loss: 93.0618\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.8155\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.8155\n",
      "Epoch 3/100\n",
      " - 1s - loss: 1.8157\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.8144\n",
      "Epoch 5/100\n",
      " - 1s - loss: 1.8150\n",
      "Epoch 6/100\n",
      " - 1s - loss: 1.8140\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.8136\n",
      "Epoch 8/100\n",
      " - 1s - loss: 1.8133\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.8125\n",
      "Epoch 10/100\n",
      " - 1s - loss: 1.8127\n",
      "Epoch 11/100\n",
      " - 1s - loss: 1.8131\n",
      "Epoch 12/100\n"
     ]
    }
   ],
   "source": [
    "# model output is next :pred_range prices normalised to 10th previous closing price\n",
    "LSTM_training_outputs = []\n",
    "for i in range(window_len, len(training_set['bt_close'])-pred_range):\n",
    "    LSTM_training_outputs.append((training_set['bt_close'][i:i+pred_range].values/\n",
    "                                  training_set['bt_close'].values[i-window_len])-1)\n",
    "LSTM_training_outputs = np.array(LSTM_training_outputs)\n",
    "\n",
    "best_model = models.fit(LSTM_training_inputs[:-pred_range], LSTM_training_outputs)\n",
    "print('Best model :')\n",
    "pp.pprint(best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
