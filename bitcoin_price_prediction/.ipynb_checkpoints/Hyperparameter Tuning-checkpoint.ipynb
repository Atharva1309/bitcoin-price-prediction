{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import *\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def build_model(optimizer, learning_rate, activation, dropout_rate,\n",
    "#                 initilizer,num_unit):\n",
    "#     keras.backend.clear_session()\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(num_unit, kernel_initializer=initilizer,\n",
    "#                     activation=activation, input_shape=(784,)))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(num_unit, kernel_initializer=initilizer,\n",
    "#                     activation=activation))\n",
    "#     model.add(Dropout(dropout_rate)) \n",
    "#     model.add(Dense(10, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy',\n",
    "#                   optimizer=optimizer(lr=learning_rate),\n",
    "#                   metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load models/lstm_model.py\n",
    "# import the relevant Keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "\"\"\"\n",
    "    If network is overfitting => decrease batch size; the contrary is true for underfitting\n",
    "\"\"\"\n",
    "def lstm_model(inputs, output_size, neurons, optimizer, loss, activ_func=\"linear\",\n",
    "                dropout=0.25): \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1446, 10, 22)\n"
     ]
    }
   ],
   "source": [
    "split_date = '2018-01-01' \n",
    "\n",
    "btc_final = pd.read_csv(\"btc_final.csv\")\n",
    "\n",
    "# Get rid of 'date' columns\n",
    "training_set, test_set = btc_final[btc_final['date']<split_date], btc_final[btc_final['date']>=split_date]\n",
    "training_set = training_set.drop('date', 1)\n",
    "test_set = test_set.drop('date', 1)\n",
    "\n",
    "window_len = 10\n",
    "norm_cols = ['bt_close','bt_volume']\n",
    "\n",
    "LSTM_training_inputs = []\n",
    "for i in range(len(training_set)-window_len):\n",
    "    temp_set = training_set[i:(i+window_len)].copy()\n",
    "    for col in norm_cols:\n",
    "        temp_set.loc[:, col] = temp_set[col]/temp_set[col].iloc[0] - 1\n",
    "    LSTM_training_inputs.append(temp_set)\n",
    "    \n",
    "LSTM_training_outputs = (training_set['bt_close'][window_len:].values/training_set['bt_close'][:-window_len].values)-1\n",
    "\n",
    "pred_range=10\n",
    "\n",
    "\n",
    "LSTM_test_inputs = []\n",
    "for i in range(len(test_set)-window_len):\n",
    "    temp_set = test_set[i:(i+window_len)].copy()\n",
    "    for col in norm_cols:\n",
    "        temp_set.loc[:, col] = temp_set[col]/temp_set[col].iloc[0] - 1\n",
    "    LSTM_test_inputs.append(temp_set)\n",
    "LSTM_test_outputs = (test_set['bt_close'][window_len:].values/test_set['bt_close'][:-window_len].values)-1\n",
    "\n",
    "\n",
    "LSTM_training_inputs = [np.array(LSTM_training_input) for LSTM_training_input in LSTM_training_inputs]\n",
    "LSTM_training_inputs = np.array(LSTM_training_inputs)\n",
    "\n",
    "print(LSTM_training_inputs[:-pred_range].shape)\n",
    "\n",
    "LSTM_test_inputs = [np.array(LSTM_test_inputs) for LSTM_test_inputs in LSTM_test_inputs]\n",
    "LSTM_test_inputs = np.array(LSTM_test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32734309  0.11248104  0.14434986 ...  0.17197482  0.07598637\n",
      " -0.06722048]\n"
     ]
    }
   ],
   "source": [
    "# training_set, test_set = btc_final[btc_final['date']<split_date], btc_final[btc_final['date']>=split_date]\n",
    "\n",
    "LSTM_training_outputs=LSTM_training_outputs[0:LSTM_training_outputs.size-10]\n",
    "print(LSTM_training_outputs)\n",
    "# LSTM_training_outputs = LSTM_training_outputs.reshape(LSTM_training_outputs.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [:1] is for testing\n",
    "# batch_size = [1, 20, 50][:1]\n",
    "# epochs = [1, 20, 50][:1]\n",
    "# learning_rate = [0.1, 0.001, 0.02][:1]\n",
    "batch_size = [20, 50, 100][:1]\n",
    "epochs = [1, 20, 50][:1]\n",
    "neurons = [10, 20][:1]\n",
    "optimizer = [SGD, RMSprop, Adagrad, Adadelta, Adam][:1]\n",
    "loss=['mae','mean_squared_error']\n",
    "activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'][:1]\n",
    "dropout_rate = [0.3, 0.25, 0.8][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Wrapper and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the wrapper and pass params to GridSearchCV\n",
    "params = dict(batch_size = batch_size,\n",
    "              epochs = epochs,\n",
    "              neurons = neurons,\n",
    "              optimizer = optimizer,\n",
    "              loss = loss,\n",
    "              activ_func = activation,\n",
    "              dropout = dropout_rate)\n",
    "\n",
    "model = KerasRegressor(build_fn=lstm_model,  verbose=2, shuffle=True)\n",
    "\n",
    "models = GridSearchCV(estimator = model, param_grid=params, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.96127011 0.60103549 0.98414411 ... 0.37250528 0.56810036 0.87350468]\n",
      "  [0.96127011 0.60103549 0.98414411 ... 0.37250528 0.56810036 0.87350468]\n",
      "  [0.96127011 0.60103549 0.98414411 ... 0.37250528 0.56810036 0.87350468]\n",
      "  ...\n",
      "  [0.91111685 0.5870407  0.98559501 ... 0.42650857 0.59139785 0.79912353]\n",
      "  [0.91111685 0.5870407  0.98559501 ... 0.42650857 0.59139785 0.79912353]\n",
      "  [0.91111685 0.5870407  0.98559501 ... 0.42650857 0.59139785 0.79912353]]\n",
      "\n",
      " [[0.96127011 0.60103549 0.98414411 ... 0.37250528 0.56810036 0.87350468]\n",
      "  [0.96127011 0.60103549 0.98414411 ... 0.37250528 0.56810036 0.87350468]\n",
      "  [0.95263217 0.5870407  0.98757471 ... 0.35430852 0.54390681 0.86118678]\n",
      "  ...\n",
      "  [0.91111685 0.5870407  0.98559501 ... 0.42650857 0.59139785 0.79912353]\n",
      "  [0.91111685 0.5870407  0.98559501 ... 0.42650857 0.59139785 0.79912353]\n",
      "  [0.9022009  0.60842538 0.98295761 ... 0.44000939 0.57885305 0.7927277 ]]\n",
      "\n",
      " [[0.96127011 0.60103549 0.98414411 ... 0.37250528 0.56810036 0.87350468]\n",
      "  [0.95263217 0.5870407  0.98757471 ... 0.35430852 0.54390681 0.86118678]\n",
      "  [0.95263217 0.5870407  0.98757471 ... 0.35430852 0.53046595 0.85254057]\n",
      "  ...\n",
      "  [0.91111685 0.5870407  0.98559501 ... 0.42650857 0.59139785 0.79912353]\n",
      "  [0.9022009  0.60842538 0.98295761 ... 0.44000939 0.57885305 0.7927277 ]\n",
      "  [0.91306725 0.61655347 0.98519951 ... 0.43883541 0.57706093 0.79497809]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.40763457 0.38451837 0.38438727 ... 0.57349143 0.29704301 0.36787872]\n",
      "  [0.4137641  0.36749017 0.37209527 ... 0.54367222 0.26792115 0.36965534]\n",
      "  [0.42379475 0.35429295 0.37186969 ... 0.53216718 0.25448029 0.38090726]\n",
      "  ...\n",
      "  [0.40484782 0.35368181 0.36545819 ... 0.51173985 0.22715054 0.35058628]\n",
      "  [0.39621021 0.35521039 0.36220118 ... 0.48415121 0.20878136 0.35899562]\n",
      "  [0.38395083 0.32789853 0.36208839 ... 0.45844095 0.20116487 0.3666943 ]]\n",
      "\n",
      " [[0.4137641  0.36749017 0.37209527 ... 0.54367222 0.26792115 0.36965534]\n",
      "  [0.42379475 0.35429295 0.37186969 ... 0.53216718 0.25448029 0.38090726]\n",
      "  [0.42379475 0.35429295 0.37186969 ... 0.53216718 0.25448029 0.38090726]\n",
      "  ...\n",
      "  [0.39621021 0.35521039 0.36220118 ... 0.48415121 0.20878136 0.35899562]\n",
      "  [0.38395083 0.32789853 0.36208839 ... 0.45844095 0.20116487 0.3666943 ]\n",
      "  [0.38395083 0.32789853 0.36208839 ... 0.45844095 0.20116487 0.3666943 ]]\n",
      "\n",
      " [[0.42379475 0.35429295 0.37186969 ... 0.53216718 0.25448029 0.38090726]\n",
      "  [0.42379475 0.35429295 0.37186969 ... 0.53216718 0.25448029 0.38090726]\n",
      "  [0.42379475 0.35429295 0.37186969 ... 0.53216718 0.25448029 0.38090726]\n",
      "  ...\n",
      "  [0.38395083 0.32789853 0.36208839 ... 0.45844095 0.20116487 0.3666943 ]\n",
      "  [0.38395083 0.32789853 0.36208839 ... 0.45844095 0.20116487 0.3666943 ]\n",
      "  [0.38395083 0.32789853 0.36208839 ... 0.45844095 0.20116487 0.3666943 ]]]\n"
     ]
    }
   ],
   "source": [
    "pred_range = 10\n",
    "# (1446, 10, 22)\n",
    "\n",
    "LSTM_training_inputs = LSTM_training_inputs[:-pred_range]\n",
    "# LSTM_training_inputs.shape(1446,22)\n",
    "print(LSTM_training_inputs[:-pred_range]) # 1446\n",
    "# best_model = models.fit(LSTM_training_inputs[:-pred_range], LSTM_training_outputs)\n",
    "# print('Best model :')\n",
    "# pp.pprint(best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
