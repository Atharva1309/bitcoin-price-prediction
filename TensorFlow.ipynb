{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    TensorFlow --> Define graph model in Python for computations\n",
    "    you'll perform, then Tf will take that graph and run it efficiently\n",
    "    using optimized C++ code; \n",
    "    \n",
    "    Some benefits of TF over competitors:\n",
    "    \n",
    "    - Runs on mobile as well\n",
    "    - Provides compatible APIs for Python and Scikit-Learn\n",
    "    - Provides TF-Slim API to simplify building, training, and evaluating NN\n",
    "    - Keras is built on top of TF\n",
    "    - Its main Python API offers much more flexibility to create all sorts\n",
    "        of computations, including any nn architectures you can think of\n",
    "    - It includes highly efficient C++ implementations of many ML operations\n",
    "        , particularly those needed for NN. + C++ API to define customized\n",
    "        high-performance operations\n",
    "    - Advanced optimization nodes to search for the params that minimize\n",
    "        a cost function!! Because TF takes care of computing the\n",
    "        gradients of the functions => they are very easy to use?\n",
    "    - Comes with TensorBoard, visualization tool, for browsing \n",
    "        through the computation graph\n",
    "    - Google has launched a cloud service to run TF graphs\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "# Linear Regression with TF\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "\n",
    "# Chief benefit of this code instead of computing the Normal Eq directly\n",
    "# using numpy, is that tf will automatically run this on your gpu - if av & tf-gpu\n",
    "\n",
    "# Next we use autodiff for computing gradients in bgd\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0, 'MSE =', 13.90306)\n",
      "('Epoch', 100, 'MSE =', 13.90306)\n",
      "('Epoch', 200, 'MSE =', 13.90306)\n",
      "('Epoch', 300, 'MSE =', 13.90306)\n",
      "('Epoch', 400, 'MSE =', 13.90306)\n",
      "('Epoch', 500, 'MSE =', 13.90306)\n",
      "('Epoch', 600, 'MSE =', 13.90306)\n",
      "('Epoch', 700, 'MSE =', 13.90306)\n",
      "('Epoch', 800, 'MSE =', 13.90306)\n",
      "('Epoch', 900, 'MSE =', 13.90306)\n"
     ]
    }
   ],
   "source": [
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = tf.gradients(mse, [theta])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GD optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = A + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " with tf.Session() as sess:\n",
    "        B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "        B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_batch(epoch, batch_index, batch_size):\n",
    "#     return X_batch, y_batch\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     for epoch in range(n_epochs):\n",
    "#         for batch_index in range(n_batches):\n",
    "#             X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "#             sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "#     best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9716347   0.9352136   0.9957704   0.995877   -0.42612398]\n",
      " [ 0.9999853   0.9990953   1.          0.99999875 -0.99958736]\n",
      " [ 1.          0.9999877   1.          1.         -0.9999998 ]\n",
      " [ 0.9660293   0.4489524  -0.99848855 -0.99995774 -1.        ]]\n",
      "[[ 1.          0.99891627  1.          1.         -0.9999999 ]\n",
      " [ 0.9962279  -0.42565945 -0.945565   -0.74405974  0.98450255]\n",
      " [ 0.9999999   0.9731786   0.9999598   0.9995155  -0.99983245]\n",
      " [ 0.9859449  -0.5882173   0.99929863 -0.9871588  -0.9998044 ]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Theory behind backprop:\n",
    "    For each training instance the BP alg first makes a prediction (\n",
    "    forward pass), measures the error, then goes through each layer \n",
    "    in reverse to measure the error contribution from each connection\n",
    "    (reverse pass), and finally slightly tweaks the connection weights\n",
    "    to reduce the error (GD step)\n",
    "    \n",
    "    In order for this alg to work properly, a key change was done to the\n",
    "    MLP's architecture: they replaecd the step function \n",
    "    with the logistic regression function: sigma(z) = 1/(1+exp(-z)). \n",
    "    This was essential because the step function contains only \n",
    "    flat segments, so there is no gradient to work with \n",
    "    because GD cannot move on a flat surface, while the logistic regression\n",
    "    aka - sigmoid, has a well-defined nonzero derivative everywhere, allowing\n",
    "    the GD to make some progress at every step. The backprop\n",
    "    may be used with various activation functions instead of logistic;\n",
    "    \n",
    "    To popular ones are:\n",
    "        - tanh(z) -- tangent fn\n",
    "        - ReLU --> is continuous but unfortunately not differentiable at z = 0\n",
    "            (the slope changes abruptly, which can make GD bounce around). \n",
    "            However, in practice it works very well and has the advantage of \n",
    "            being fast to compute. Most importantly, the fact that it \n",
    "            doesn't have a maximum output value also helps reduce \n",
    "            some issues during GD. \n",
    "            \n",
    "            \n",
    "    Fine-Tuning Neural Network Hyperparameters\n",
    "    \n",
    "        \n",
    "    The flexibility of nn is a double-edged sword: there are simply \n",
    "    many hyperparams to tweak. Not only can you use any imaginable \n",
    "    network topology, but even in a simple MLP you can change the \n",
    "    number of layers, the number of neurons per layer, \n",
    "    the type of activation function to use in each layer, the weight \n",
    "    initialization logic etc. \n",
    "    How to know what combination of hyperparams is best for your task?\n",
    "    \n",
    "    \n",
    "    1. Number of hidden layers:\n",
    "        \n",
    "        Because MLPs with a single hidden layer and enough neurons\n",
    "        gives reasonable results, deeper architectures were not considered;\n",
    "        But they had overlooked the fact that DEEP NETWORKS HAVE \n",
    "        A MUCH HIGHER __PARAMETER EFFICIENCY__ than shallow ones:\n",
    "        Because they can model complex functions\n",
    "        with less neurons in hidden layers => much faster to train!\n",
    "    \n",
    "    \n",
    "    2. Number of neurons per Hidden Layer:\n",
    "        \n",
    "        For the input and output layers, this is already predetermined by \n",
    "        the task at hand. As for the hidden layers, a common practice is to size them to form a funnel, with fewer\n",
    "        and fewer neurons at each layer — the rationale being that many low-level features can coalesce into far\n",
    "        fewer high-level features.\n",
    "        \n",
    "    3. Activation Functions:\n",
    "    \n",
    "        In most cases you can use the:\n",
    "        \n",
    "            ___ReLU___ activation funtion \n",
    "            in the hidden layers (or one of its variants). It is a bit FASTER\n",
    "            to compute than other atc fn. Also GD doesn't get stuck as much\n",
    "            on plateaous, thanks to the fact that it does not saturate \n",
    "            for large input values (as opposed to the logistic function\n",
    "            or the hyperbolic tanh fn which saturate)\n",
    "            \n",
    "        For the output layer, the ___softmax___ act fn is generally good\n",
    "        for classification tasks, as for regression tasks, you can simply use\n",
    "        no activation fn at all. \n",
    "        \n",
    "        \n",
    "\n",
    "    The BIG ISSUE OF: Vanishing/Exploding Gradients Problems\n",
    "    \n",
    "    Because we'll be using Backprop as a training alg, and it goes from \n",
    "    the output layer to the input layer, propagating the error gradient\n",
    "    on the way. Once the algorithm has computed the gradient of the cost\n",
    "    function with regards to each parameter in the network, it uses these \n",
    "    gradients to UPDATE EACH PARAM WITH A GD STEP; \n",
    "    \n",
    "    Unfortunately, gradients often get smaller and smaller as the alg \n",
    "    progresses down to the lower layers. As a result, the GD update\n",
    "    leaves the lower layer connection weights virtually unchanged, and \n",
    "    training never converges to a good solution (So divergence can occur\n",
    "    on two cases: 1. Too large learning rate 2. Vanishing GD). Vice-versa \n",
    "    is called exploding GD, which is mostly encountered in RNN; \n",
    "    \n",
    "    this was one of the reasons why dnn were abandoned for a long time. \n",
    "    Until Glorot and Bengio found a new suspect.\n",
    "    \n",
    "    Why was this they asked? It seemed that the combination of \n",
    "    logistic sigmoid act fn with a classical set up for weight initialization\n",
    "    , namely random init using a normal distribution with a mean \n",
    "    of 0 and a standard deviation of 1. => this makes the variance \n",
    "    of the outputs of each layer much greater than the variance of its inputs\n",
    "    So going foward in the network, the variance keeps increasing \n",
    "    after each layer until the activation fn saturates at the top layers. \n",
    "    This is actually made worse by the fact that the logistic fn has a \n",
    "    mean of .5, not 0 like tanh (which behaves slightly better in dnn). \n",
    "    \n",
    "    fix: variance of outputs of each layer to == variance of layers inputs\n",
    "        + gradients should have equal variance before and after flowing through\n",
    "        a layer in the reverse direction. \n",
    "        \n",
    "        They gave the Xavier initialization strategy. \n",
    "        \n",
    "        Act fn have either uniform or normal distribution\n",
    "        \n",
    "\n",
    "    Faster Optimizers:\n",
    "        Training a very large deep neural network can be painfully slow. \n",
    "        Huge speed can be guaranteed optimizers other than GD, most populars:\n",
    "            - Momentum optimization\n",
    "            - Nesterov Accelerated Gradient\n",
    "            - AdaGrad\n",
    "            - RMSProp\n",
    "            - Adam optimizer - optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "    Regularization:\n",
    "        - The most pop in dnn: ___Dropout___ :D. \n",
    "        - ___Max-Norm Regularization___\n",
    "        \n",
    "    Most cases you would pick:\n",
    "    \n",
    "        Initialization --------> He init. \n",
    "        Activation Function ---> ELU\n",
    "        Normalization ---------> Batch \n",
    "        Regularization --------> Dropout\n",
    "        Optimizaer ------------> Nesteroc Accelerated Gradient\n",
    "        Learning rate schedule - none\n",
    "\"\"\"\n",
    "\n",
    "# rnn\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons],dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons,n_neurons],dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Mini-batch\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) \n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    \n",
    "print(Y0_val)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_steps = 28\n",
    "n_outputs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1],\n",
    "dtype=tf.float32)\n",
    "\n",
    "Y0, Y1 = output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2]))\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs,\n",
    "                                                dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "####### Predicting Stock Prices\n",
    "#######################################################################\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# unroll over 20 time steps, since each sequence\n",
    "# will be 20 inputs long.\n",
    "n_steps = 20     \n",
    "# each input will contain only one feature (the value at \n",
    "# that time)    \n",
    "n_inputs = 1\n",
    "n_neurons = 100 # 100 recurrent neurons\n",
    "n_outputs = 1\n",
    "\n",
    "# The targets are also sequences of 20 inputs, \n",
    "# each containing a single value\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
